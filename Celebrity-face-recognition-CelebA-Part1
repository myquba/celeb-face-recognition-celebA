{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1mtwOkdgKfaOcL6t_OvCgn0gDOctHppG2",
      "authorship_tag": "ABX9TyOsHDWLJNmE/7M87A80g5iM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myquba/celeb-face-recognition-celebA/blob/main/Celebrity-face-recognition-CelebA-Part1\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4_uXl9F7Abx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "hrP7rDGr7Dcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9eCmQSs8Bat",
        "outputId": "e4c9e639-86de-4e8b-d58e-4dc11c19d234"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Colab Notebooks/Copy of part2.zip'\n",
        "extract_folder = '/content/celebrity_dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "# Check the extracted content\n",
        "os.listdir(extract_folder)[:10]  # Display the first 10 item"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9peYZ-aG8wag",
        "outputId": "5ba0ceb2-2ee9-450e-caec-4f9ba380298d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dir_001']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQhTH-DvYQZz",
        "outputId": "e7ca757c-1701-4b5d-be19-8fcc0f70b011"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.6)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566169 sha256=6ff9bae8662adc3613b7972b5b1a7ee4e1e8912d49e9e71d2e3528ce8ddc8792\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "\n",
        "# Base directory\n",
        "base_dir = '/content/celebrity_dataset'  # <-- Adjust if your dataset's root folder has a different path\n",
        "\n",
        "# Directory for 'dir_001' - You can change this to 'dir_002', 'dir_003', etc. based on which directory you want to process\n",
        "dir_path = os.path.join(base_dir, 'dir_001')\n",
        "\n",
        "# Selecting the first celebrity in the 'dir_001' folder - If you want to process another celebrity, change the index\n",
        "celebrity_name = os.listdir(dir_path)[0]\n",
        "celebrity_folder = os.path.join(dir_path, celebrity_name)\n",
        "\n",
        "encodings = []\n",
        "\n",
        "# Number of images to process per celebrity for this demo\n",
        "num_images_per_celebrity = 10  # <-- Adjust if you want to process a different number of images\n",
        "\n",
        "# For each image of the selected celebrity, compute face encoding\n",
        "for img_name in os.listdir(celebrity_folder)[:num_images_per_celebrity]:\n",
        "    img_path = os.path.join(celebrity_folder, img_name)\n",
        "\n",
        "    # Load image and compute face encoding\n",
        "    image = face_recognition.load_image_file(img_path)\n",
        "    encoding = face_recognition.face_encodings(image)\n",
        "\n",
        "    # Some images might not have faces or might have issues, so we check before appending\n",
        "    if len(encoding) > 0:\n",
        "        encodings.append(encoding[0])\n",
        "\n",
        "# Compute the average encoding for this celebrity\n",
        "if encodings:\n",
        "    average_encoding = np.mean(encodings, axis=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "27UQFGmdapcT",
        "outputId": "19c78aa5-fbbe-4af2-91b5-3325fc381953"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d088fc0f4880>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Base directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-dom90fo7/dlib_83740b879f974cfc8f34b85c06d7b8fd/dlib/cuda/gpu_data.cpp:204. code: 100, reason: no CUDA-capable device is detected"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv-ayiBod4sy",
        "outputId": "44d2b187-b5d3-4343-be03-10597b347c0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgheVhDeshP",
        "outputId": "b16005e6-5f74-40ec-cdc6-f5f995fce7bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.6)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (9.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566169 sha256=0306b6c9d11b105e082e75ad7791bd45ed8fc9d883c2cc7882e335a23808fce7\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/eb/cf/e9eced74122b679557f597bb7c8e4c739cfcac526db1fd523d\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036PGaaAe8GM",
        "outputId": "bd62dfdb-901e-47cf-c413-e75ca41651fa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dlib 19.24.2\n",
            "Uninstalling dlib-19.24.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/_dlib_pybind11.cpython-310-x86_64-linux-gnu.so\n",
            "    /usr/local/lib/python3.10/dist-packages/dlib-19.24.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/dlib/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled dlib-19.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YexO5pnlADGz",
        "outputId": "3f3f76a8-c34f-4bea-c9fc-136073b232fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dlib\n",
            "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: dlib\n",
            "  Building wheel for dlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dlib: filename=dlib-19.24.2-cp310-cp310-linux_x86_64.whl size=4336956 sha256=2bb0cb33c9cd6d3c32bf0ac34c061a266336ca3eeed57cdbd7eacdd1e3eeb1e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/e2/80/888fdc098db86b463ff0c83ae5e5ca151889e901bc1e9a3a11\n",
            "Successfully built dlib\n",
            "Installing collected packages: dlib\n",
            "Successfully installed dlib-19.24.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "\n",
        "# Base directory\n",
        "base_dir = '/content/celebrity_dataset'  # <-- Adjust if your dataset's root folder has a different path\n",
        "\n",
        "# Directory for 'dir_001' - You can change this to 'dir_002', 'dir_003', etc. based on which directory you want to process\n",
        "dir_path = os.path.join(base_dir, 'dir_001')\n",
        "\n",
        "# Selecting the first celebrity in the 'dir_001' folder - If you want to process another celebrity, change the index\n",
        "celebrity_name = os.listdir(dir_path)[0]\n",
        "celebrity_folder = os.path.join(dir_path, celebrity_name)\n",
        "\n",
        "encodings = []\n",
        "\n",
        "# Number of images to process per celebrity for this demo\n",
        "num_images_per_celebrity = 10  # <-- Adjust if you want to process a different number of images\n",
        "\n",
        "# For each image of the selected celebrity, compute face encoding\n",
        "for img_name in os.listdir(celebrity_folder)[:num_images_per_celebrity]:\n",
        "    img_path = os.path.join(celebrity_folder, img_name)\n",
        "\n",
        "    # Load image and compute face encoding\n",
        "    image = face_recognition.load_image_file(img_path)\n",
        "    encoding = face_recognition.face_encodings(image)\n",
        "\n",
        "    # Some images might not have faces or might have issues, so we check before appending\n",
        "    if len(encoding) > 0:\n",
        "        encodings.append(encoding[0])\n",
        "\n",
        "# Compute the average encoding for this celebrity\n",
        "if encodings:\n",
        "    average_encoding = np.mean(encodings, axis=0)\n",
        "print(celebrity_name)\n",
        "print(f\"Number of images processed: {len(encodings)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUw5_ydXH4pI",
        "outputId": "c90c14c4-bd0c-439d-ab5b-0e8fcc0260ba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Andy Murray\n",
            "Number of images processed: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import pickle\n",
        "\n",
        "# Base directory\n",
        "base_dir = '/content/celebrity_dataset'\n",
        "\n",
        "# Directory for 'dir_001'\n",
        "dir_path = os.path.join(base_dir, 'dir_001')\n",
        "\n",
        "# Lists to store celebrity names and their average face encodings\n",
        "all_celebrity_encodings = []\n",
        "all_celebrity_names = []\n",
        "\n",
        "# Number of celebrities to process for this batch\n",
        "batch_size = 10\n",
        "\n",
        "# Iterate through a batch of celebrity folders inside the directory\n",
        "for celebrity_name in os.listdir(dir_path)[:batch_size]:\n",
        "    celebrity_folder = os.path.join(dir_path, celebrity_name)\n",
        "    encodings = []\n",
        "\n",
        "   # For each image of the celebrity, compute face encoding\n",
        "for img_name in os.listdir(celebrity_folder)[:num_images_per_celebrity]:\n",
        "    img_path = os.path.join(celebrity_folder, img_name)\n",
        "\n",
        "    try:\n",
        "        # Load image and compute face encoding\n",
        "        image = face_recognition.load_image_file(img_path)\n",
        "        encoding = face_recognition.face_encodings(image)\n",
        "\n",
        "        # Some images might not have faces or might have issues, so we check before appending\n",
        "        if len(encoding) > 0:\n",
        "            encodings.append(encoding[0])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {img_path}: {e}\")\n",
        "\n",
        "    # Compute the average encoding for this celebrity and store\n",
        "    if encodings:\n",
        "        average_encoding = np.mean(encodings, axis=0)\n",
        "        all_celebrity_encodings.append(average_encoding)\n",
        "        all_celebrity_names.append(celebrity_name)\n",
        "\n",
        "# Save the results to a file\n",
        "with open('/content/celebrity_encodings_batch1.pkl', 'wb') as file:\n",
        "    pickle.dump((all_celebrity_names, all_celebrity_encodings), file)\n",
        "\n",
        "print(f\"Processed {len(all_celebrity_names)} celebrities from dir_001.\")\n"
      ],
      "metadata": {
        "id": "WOSsBf4lLSAB",
        "outputId": "092592de-d87c-4db9-9448-267d2dbfffcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10 celebrities from dir_001.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists to store celebrity names and their average face encodings\n",
        "all_celebrity_encodings_next90 = []\n",
        "all_celebrity_names_next90 = []\n",
        "\n",
        "# Indices for processing the next 90 celebrities\n",
        "start_index = batch_size\n",
        "end_index = start_index + 90\n",
        "\n",
        "# Iterate through the next 90 celebrity folders inside the directory\n",
        "for celebrity_name in os.listdir(dir_path)[start_index:end_index]:\n",
        "    celebrity_folder = os.path.join(dir_path, celebrity_name)\n",
        "    encodings = []\n",
        "\n",
        "    # For each image of the celebrity, compute face encoding\n",
        "    for img_name in os.listdir(celebrity_folder)[:num_images_per_celebrity]:\n",
        "        img_path = os.path.join(celebrity_folder, img_name)\n",
        "\n",
        "        try:\n",
        "            # Load image and compute face encoding\n",
        "            image = face_recognition.load_image_file(img_path)\n",
        "            encoding = face_recognition.face_encodings(image)\n",
        "\n",
        "            # Some images might not have faces or might have issues, so we check before appending\n",
        "            if len(encoding) > 0:\n",
        "                encodings.append(encoding[0])\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {img_path}: {e}\")\n",
        "\n",
        "    # Compute the average encoding for this celebrity and store\n",
        "    if encodings:\n",
        "        average_encoding = np.mean(encodings, axis=0)\n",
        "        all_celebrity_encodings_next90.append(average_encoding)\n",
        "        all_celebrity_names_next90.append(celebrity_name)\n",
        "\n",
        "# Save the results to a new file\n",
        "with open('/content/celebrity_encodings_next90.pkl', 'wb') as file:\n",
        "    pickle.dump((all_celebrity_names_next90, all_celebrity_encodings_next90), file)\n",
        "\n",
        "print(f\"Processed {len(all_celebrity_names_next90)} celebrities from dir_001.\")\n"
      ],
      "metadata": {
        "id": "A2ANpPF-NHze",
        "outputId": "efd92624-5546-44b3-c709-298af3843bd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing image /content/celebrity_dataset/dir_001/Angelina Jolie/151.jpg: cannot identify image file '/content/celebrity_dataset/dir_001/Angelina Jolie/151.jpg'\n",
            "Error processing image /content/celebrity_dataset/dir_001/Anthony Hopkins/658.jpg: cannot identify image file '/content/celebrity_dataset/dir_001/Anthony Hopkins/658.jpg'\n",
            "Error processing image /content/celebrity_dataset/dir_001/Barbra Streisand/475.jpg: cannot identify image file '/content/celebrity_dataset/dir_001/Barbra Streisand/475.jpg'\n",
            "Error processing image /content/celebrity_dataset/dir_001/Arnold Schwarzenegger/214.jpg: cannot identify image file '/content/celebrity_dataset/dir_001/Arnold Schwarzenegger/214.jpg'\n",
            "Processed 90 celebrities from dir_001.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_celebrity_lookalike(user_image_path, all_celebrity_names, all_celebrity_encodings):\n",
        "    \"\"\"\n",
        "    Compare the user's face encoding to all celebrity encodings and return the closest match.\n",
        "\n",
        "    Parameters:\n",
        "    - user_image_path: Path to the user's image.\n",
        "    - all_celebrity_names: List of celebrity names.\n",
        "    - all_celebrity_encodings: List of face encodings for the celebrities.\n",
        "\n",
        "    Returns:\n",
        "    - Closest celebrity match.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the user's image and compute the face encoding\n",
        "    user_image = face_recognition.load_image_file(user_image_path)\n",
        "    user_encoding = face_recognition.face_encodings(user_image)\n",
        "\n",
        "    # Check if a face is detected in the user's image\n",
        "    if not user_encoding:\n",
        "        return \"No face detected in the image.\"\n",
        "\n",
        "    # Find the face distances for the user's face encoding with all celebrity encodings\n",
        "    face_distances = face_recognition.face_distance(all_celebrity_encodings, user_encoding[0])\n",
        "\n",
        "    # Find the index of the celebrity with the smallest face distance\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "\n",
        "    # Return the name of the celebrity with the closest match\n",
        "    return all_celebrity_names[best_match_index]\n"
      ],
      "metadata": {
        "id": "ExPCVPf_RH3Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the previously saved celebrity encodings\n",
        "with open('/content/celebrity_encodings_batch1.pkl', 'rb') as file:\n",
        "    celeb_names_batch1, celeb_encodings_batch1 = pickle.load(file)\n",
        "with open('/content/celebrity_encodings_next90.pkl', 'rb') as file:\n",
        "    celeb_names_next90, celeb_encodings_next90 = pickle.load(file)\n",
        "\n",
        "# Combine encodings and names from both batches\n",
        "all_names = celeb_names_batch1 + celeb_names_next90\n",
        "all_encodings = celeb_encodings_batch1 + celeb_encodings_next90\n",
        "\n",
        "# Path to the user's image\n",
        "user_image_path = '/content/drive/MyDrive/adele.jpg'\n",
        "\n",
        "# Find and print the celebrity lookalike\n",
        "lookalike = find_celebrity_lookalike(user_image_path, all_names, all_encodings)\n",
        "print(f\"The closest celebrity lookalike is: {lookalike}\")\n"
      ],
      "metadata": {
        "id": "JlXwOlMyRQQE",
        "outputId": "1462e32e-b4ee-4f9e-f414-dfb8f472bb6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The closest celebrity lookalike is: Adele\n"
          ]
        }
      ]
    }
  ]
}